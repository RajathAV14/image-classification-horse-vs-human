{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
    "### Horse vs Human classification using my own dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and validation together using image data generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training using the bad coursera data - pencil human and fat horse- shows how misrepresentative the training dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 74 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-24-185683fe39ec>:24: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 8 steps, validate for 4 steps\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 887ms/step - loss: 0.7763 - accuracy: 0.5098 - val_loss: 0.7311 - val_accuracy: 0.5781\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 5s 633ms/step - loss: 0.8621 - accuracy: 0.6608 - val_loss: 0.7462 - val_accuracy: 0.5000\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 5s 587ms/step - loss: 0.4116 - accuracy: 0.8625 - val_loss: 1.8584 - val_accuracy: 0.5312\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 0.3337 - accuracy: 0.8647 - val_loss: 2.2212 - val_accuracy: 0.5156\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 5s 644ms/step - loss: 0.2921 - accuracy: 0.8867 - val_loss: 2.1264 - val_accuracy: 0.5312\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 5s 659ms/step - loss: 0.3649 - accuracy: 0.8867 - val_loss: 3.8727 - val_accuracy: 0.5000\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 0.4336 - accuracy: 0.8262 - val_loss: 1.4884 - val_accuracy: 0.5312\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 5s 642ms/step - loss: 0.1020 - accuracy: 0.9668 - val_loss: 2.0830 - val_accuracy: 0.5000\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 0.1064 - accuracy: 0.9623 - val_loss: 3.4257 - val_accuracy: 0.5781\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 5s 566ms/step - loss: 0.1018 - accuracy: 0.9579 - val_loss: 2.3549 - val_accuracy: 0.5312\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 0.3661 - accuracy: 0.8789 - val_loss: 1.5274 - val_accuracy: 0.5156\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 0.0941 - accuracy: 0.9579 - val_loss: 2.3983 - val_accuracy: 0.5312\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 5s 629ms/step - loss: 0.0350 - accuracy: 0.9863 - val_loss: 2.7579 - val_accuracy: 0.5625\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 0.0230 - accuracy: 0.9956 - val_loss: 2.6273 - val_accuracy: 0.6094\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 6s 699ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 3.9918 - val_accuracy: 0.5312\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 7s 925ms/step - loss: 0.5216 - accuracy: 0.8887 - val_loss: 2.0050 - val_accuracy: 0.5625\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 43s 5s/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.8930 - val_accuracy: 0.5469\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 15s 2s/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.5628 - val_accuracy: 0.5781\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 7s 893ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1747 - val_accuracy: 0.5469\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 6s 763ms/step - loss: 0.2021 - accuracy: 0.9446 - val_loss: 1.8705 - val_accuracy: 0.4844\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 6s 783ms/step - loss: 0.0445 - accuracy: 0.9863 - val_loss: 2.9713 - val_accuracy: 0.5469\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 3.7353 - val_accuracy: 0.5938\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 7s 847ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.2037 - val_accuracy: 0.5781\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 4s 544ms/step - loss: 6.2901e-04 - accuracy: 1.0000 - val_loss: 4.8526 - val_accuracy: 0.5781\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 4s 555ms/step - loss: 0.3852 - accuracy: 0.9082 - val_loss: 2.2233 - val_accuracy: 0.5781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21010a68fc8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=16\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\horsehuman',     \n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=64,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\test',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=8 ,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=74 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 2 classes.\n",
      "WARNING:tensorflow:From <ipython-input-25-4e1890cba7f0>:12: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "32/32 [==============================] - 3s 85ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_datagen = ImageDataGenerator(rescale=1./255)\n",
    "prediction_generator = predict_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\new_images',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "pred=model.predict_generator(\n",
    "        prediction_generator, \n",
    "        steps=len(prediction_generator),\n",
    "        verbose=1\n",
    "        )    # gives a 1d array of class probabilities. in this case, a single probability\n",
    "pred=pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for converting probailites into the corresponding predicted classes\n",
    "predicted_class_indices=[] \n",
    "for i in pred:\n",
    "    if i<0.5:\n",
    "        predicted_class_indices.append(0)\n",
    "    else:\n",
    "        predicted_class_indices.append(1)        \n",
    "# predicted_class_indices=np.argmax(pred,axis=1)   <- use this instead of above code if a multi class classification is used\n",
    "\n",
    "\n",
    "# for getting the actual class labels\n",
    "true_labels= [] \n",
    "classlabel=0\n",
    "for i in os.listdir(r'C:\\Users\\User\\Desktop\\new_images'):\n",
    "    j=os.path.join(r'C:\\Users\\User\\Desktop\\new_images',i)\n",
    "    l=len(os.listdir(j))\n",
    "    for k in range(l):\n",
    "        true_labels.append(classlabel)\n",
    "    classlabel+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=tf.math.confusion_matrix(labels=true_labels,predictions=predicted_class_indices)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sn.heatmap(cm,annot=True, linewidth=0.5)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using my own data for training and coursera data for validation with image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 images belonging to 2 classes.\n",
      "Found 1027 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 3 steps, validate for 32 steps\n",
      "Epoch 1/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.9327 - accuracy: 0.6429 - val_loss: 0.1803 - val_accuracy: 0.9375\n",
      "Epoch 2/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.8939 - accuracy: 0.5000 - val_loss: 0.3853 - val_accuracy: 0.8623\n",
      "Epoch 3/25\n",
      "3/3 [==============================] - 9s 3s/step - loss: 0.6654 - accuracy: 0.5952 - val_loss: 0.4529 - val_accuracy: 0.7803\n",
      "Epoch 4/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.5966 - accuracy: 0.7083 - val_loss: 0.3735 - val_accuracy: 0.8740\n",
      "Epoch 5/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5891 - accuracy: 0.6458 - val_loss: 0.3913 - val_accuracy: 0.8076\n",
      "Epoch 6/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.7014 - accuracy: 0.5833 - val_loss: 0.4917 - val_accuracy: 0.7832\n",
      "Epoch 7/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5521 - accuracy: 0.7292 - val_loss: 0.4903 - val_accuracy: 0.7920\n",
      "Epoch 8/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5541 - accuracy: 0.7381 - val_loss: 0.5986 - val_accuracy: 0.6904\n",
      "Epoch 9/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5222 - accuracy: 0.7143 - val_loss: 0.5260 - val_accuracy: 0.7539\n",
      "Epoch 10/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.7319 - accuracy: 0.7083 - val_loss: 0.6653 - val_accuracy: 0.5254\n",
      "Epoch 11/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.6924 - accuracy: 0.5208 - val_loss: 0.5800 - val_accuracy: 0.7002\n",
      "Epoch 12/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5940 - accuracy: 0.7083 - val_loss: 0.5429 - val_accuracy: 0.6973\n",
      "Epoch 13/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5704 - accuracy: 0.6429 - val_loss: 0.4168 - val_accuracy: 0.8125\n",
      "Epoch 14/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5074 - accuracy: 0.6905 - val_loss: 0.6005 - val_accuracy: 0.7305\n",
      "Epoch 15/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5834 - accuracy: 0.7143 - val_loss: 0.4866 - val_accuracy: 0.7676\n",
      "Epoch 16/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5604 - accuracy: 0.6875 - val_loss: 0.5059 - val_accuracy: 0.7480\n",
      "Epoch 17/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.4857 - accuracy: 0.8125 - val_loss: 0.4582 - val_accuracy: 0.7871\n",
      "Epoch 18/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.5493 - accuracy: 0.7708 - val_loss: 0.4373 - val_accuracy: 0.8018\n",
      "Epoch 19/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5461 - accuracy: 0.6429 - val_loss: 0.5336 - val_accuracy: 0.7656\n",
      "Epoch 20/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.4722 - accuracy: 0.6875 - val_loss: 0.8076 - val_accuracy: 0.7568\n",
      "Epoch 21/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.5075 - accuracy: 0.7619 - val_loss: 0.7009 - val_accuracy: 0.7734\n",
      "Epoch 22/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.4399 - accuracy: 0.7857 - val_loss: 2.0052 - val_accuracy: 0.7295\n",
      "Epoch 23/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.0362 - accuracy: 0.7619 - val_loss: 0.5674 - val_accuracy: 0.7490\n",
      "Epoch 24/25\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.5593 - accuracy: 0.6667 - val_loss: 0.6086 - val_accuracy: 0.6562\n",
      "Epoch 25/25\n",
      "3/3 [==============================] - 11s 4s/step - loss: 0.5248 - accuracy: 0.7083 - val_loss: 0.6173 - val_accuracy: 0.6777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x210814caa08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255,   # All images will be rescaled by 1./255\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\test',     \n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=16,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\horsehuman',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3 ,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1024 // 32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "higher validation accuracy than previous case shows the effect of a good, representative training dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 2 classes.\n",
      "32/32 [==============================] - 1s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_datagen = ImageDataGenerator(rescale=1./255)\n",
    "prediction_generator = predict_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\new_images',\n",
    "        target_size=(300, 300),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "pred=model.predict_generator(\n",
    "        prediction_generator, \n",
    "        steps=len(prediction_generator),\n",
    "        verbose=1\n",
    "        )    # gives a 1d array of class probabilities. in this case, a single probability\n",
    "pred=pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for converting probailites into the corresponding predicted classes\n",
    "predicted_class_indices=[] \n",
    "for i in pred:\n",
    "    if i<0.5:\n",
    "        predicted_class_indices.append(0)\n",
    "    else:\n",
    "        predicted_class_indices.append(1)        \n",
    "# predicted_class_indices=np.argmax(pred,axis=1)   <- use this instead of above code if a multi class classification is used\n",
    "\n",
    "\n",
    "# for getting the actual class labels\n",
    "true_labels= [] \n",
    "classlabel=0\n",
    "for i in os.listdir(r'C:\\Users\\User\\Desktop\\new_images'):\n",
    "    j=os.path.join(r'C:\\Users\\User\\Desktop\\new_images',i)\n",
    "    l=len(os.listdir(j))\n",
    "    for k in range(l):\n",
    "        true_labels.append(classlabel)\n",
    "    classlabel+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAFBCAYAAACy3D+0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYdElEQVR4nO3de7SddX3n8fcnQOQWbiKMgoqoxVE7wkwGEWYYFEUEFaG6Ki0KSD1ap4q9WLHaUpe9MLW6Rp0Zy6ncKhrvUUamXIsgFCgIFIOgWBQMWCIiIEEmhPOdP86mPZwJyd47Z5/9O3ner6xnZe/n7P0836gxn/X9XZ5UFZIkSa1ZNO4CJEmS1sWQIkmSmmRIkSRJTTKkSJKkJhlSJElSkwwpkiSpSYYUSZI0Z5KcnmRVkhUzzn0oyY1JbkhyQZKn9XUt90mRJElzJcmBwIPA31TVC3vntquqB3qv3wU8v6revqFr2UmRJElzpqouA+6dde6BGW+3AfrqkGw+h3VJkiStU5I/Bd4M3A+8tK/vNDzc02xhkiSNSObzZo/cc9vA/9Yufsqz3wZMzDg1WVWTMz+TZA/g648N98z62fuALavq5A3dq+mQcv/xLx93DVLnbH/GRWy+eLdxlyF1zto1d8ICCClb7LznBmvcQEh5JnDuun42m8M9kiR11dSj83KbJM+tqlt7b18L3NLP9wwpkiR1VU3N+SWTLAMOAnZOshI4GTgsyV7AFHA7sMGVPWBIkSSpu6bmPqRU1dHrOH3aMNcypEiS1FE1gk7KXDKkSJLUVSPopMwlQ4okSV1lJ0WSJDVpnlb3DMuQIklSV9lJkSRJTXJOiiRJapGreyRJUpvspEiSpCbZSZEkSU1ydY8kSWqSnRRJktQk56RIkqQmNd5JWTTuAiRJktbFTookSV3lcI8kSWpRlat7JElSixqfk2JIkSSpqxzukSRJTbKTIkmSmuSOs5IkqUmNd1LcJ0WSpK6amhr82IAkpydZlWTFjHMfTnJLkhuTLE+yQz/lGVIkSeqqmhr82LAzgUNnnbsQeGFV/Tvge8D7+rmQIUWSpK4aQSelqi4D7p117oKqWtt7exWwez/lOSdFkqSuGs8S5LcAn+/ng4YUSZI6apgdZ5NMABMzTk1W1WSf330/sBb4TD+fN6RIktRVQ3RSeoGkr1AyU5JjgVcDB1dV9fMdQ4okSV01T0uQkxwKvBf4L1X1UL/fM6RIktRVI5iTkmQZcBCwc5KVwMlMr+Z5EnBhEoCrqurtG7qWIUWSpK4aQSelqo5ex+nThrmWS5AlSVKT7KRIktRVPgVZkiQ1qfFn9xhSJEnqKjspkiSpSYYUSZLUJId7JElSk+ykSJKkJtlJkSRJTbKTIkmSmmQnRZIkNclOiiRJapIhRZIkNalq3BWslyFFkqSuspMiSZKaZEiRJElNcnWPJElqUuOdlEXjLkCSJGld7KRIktRVru6RJElNany4x5AiSVJXGVIkSVKTGl/d48RZSZI6qqZq4GNDkpyeZFWSFTPOvSHJTUmmkizttz5DiiRJXTU1NfixYWcCh846twI4CrhskPIc7pEkqatGMNxTVZcl2WPWuZsBkgx0LTspkiR11VQNfCSZSHLtjGNiVOXZSZEkqauGWN1TVZPA5NwX8/8zpEiS1FUuQdambqu3/B6bv+jF1AP38eAfvhWAbLOErX7zAyzaeVem7rmbh/7Xh+ChB8dcqbRpW7RoEVdf9bfcdec/c8SRx467HC0Eje8465wUbbQ1l5/P6o++73HnnnTYG3n0O9fz4EnH8eh3rmfLw984puqk7njXO3+DW265ddxlaCEZweqeJMuAK4G9kqxMckKSI5OsBF4CnJvk/H7KM6Rooz36vW9TD/78cec232d/1lxxAQBrrriAzfc5YBylSZ2x225P5bBXHczppy8bdylaSIaYOLshVXV0VT21qraoqt2r6rSqWt57/aSq2rWqXtlPeSMb7knyPOAIYDeggLuAcx5bhqRN26Ltd6TuvxeAuv9eFm23w3gLkjZxH/3IBznpfX/CkiXbjrsULSRd3HE2yXuBzwEB/gG4pvd6WZKTRnFPSeqqww97OatW3cN113973KVooRlBJ2UujaqTcgLwgqp6ZObJJB8FbgJOWdeXemutJwBOPfVUfnVExWn0pu7/Gdl+J+r+e8n2OzH1wH3jLknaZO2//1Je8+pDeNWhL2PLLZ/Edtst4awzP86xx71r3KWpcdX46p5RzUmZAp62jvNP7f1snapqsqqWVtXSiYmR7Q2jebD2hitZfMAhACw+4BDWXv/3Y65I2nS9/wOnsMeeS3nOL+3Hrx/zDi655AoDijYJo+qkvBu4OMmtwI96554BPAf4rRHdU2Oy1dv+gM2f9yKy7fYs+cgyHv7qWfzfcz/H1u/4AFsceCj101XTS5AlSW2Z5+GbQaVGtEY6ySJgX6YnzgZYCVxTVY/2eYm6//iXj6Q2SU9s+zMuYvPFu427DKlz1q65E6b/vZw3q//kmIFDwDYfOHveahzZ6p6qmgKuGtX1JUnSRmq8k+KOs5IkdVXjE2cNKZIkdZWdFEmS1KTGN3MzpEiS1FV2UiRJUota38zNkCJJUlfZSZEkSU0ypEiSpCY5cVaSJDXJTookSWpRGVIkSVKTDCmSJKlJLkGWJElNspMiSZKa1HhIWTTuAiRJ0qYjyelJViVZMePcTkkuTHJr7/cd+7mWIUWSpI6qqoGPPpwJHDrr3EnAxVX1XODi3vsNMqRIktRVUzX4sQFVdRlw76zTRwBn9V6fBbyun/KckyJJUlfN35yUXavqxwBV9eMku/TzJUOKJEkdNcxmbkkmgIkZpyaranLOiprBkCJJUlcNEVJ6gWTQUHJ3kqf2uihPBVb18yXnpEiS1FVTQxzDOQc4tvf6WOBr/XzJTookSR01imf3JFkGHATsnGQlcDJwCvCFJCcAdwBv6OdahhRJkrpqBCGlqo5+gh8dPOi1DCmSJHVV24/uMaRIktRVoxjumUuGFEmSuspOiiRJapGdFEmS1CY7KZIkqUVlSJEkSU0ypEiSpBa13klxW3xJktQkOymSJHVV450UQ4okSR3V+nCPIUWSpI4ypEiSpCYZUiRJUpsq465gvQwpkiR1lJ0USZLUpJqykyJJkhpkJ0WSJDWpnJMiSZJaZCdFkiQ1yTkpkiSpSVXjrmD9fMCgJEkdVVMZ+OhHkhOTrEhyU5J3D1ufnRRJkjpqFMM9SV4IvBXYF1gDnJfk3Kq6ddBr2UmRJKmjqgY/+vBvgauq6qGqWgtcChw5TH2GFEmSOmpEwz0rgAOTPDnJ1sBhwNOHqc/hHkmS1LckE8DEjFOTVTX52JuqujnJfwMuBB4E/hFYO8y9DCmSJHXUMJu59QLJ5AY+cxpwGkCSPwNWDlOfIUWSpI4a1WZuSXapqlVJngEcBbxkmOusN6Qk+TmwrmkyAaqqthvmppIkafymRrct/peTPBl4BPivVfWzYS6y3pBSVUuGuagkSWrfqJ7dU1X/eS6uM9BwT5JdgC1nFHHHXBQhSZLmX+vb4ve1BDnJa5PcCvyA6fXOPwT+doR1SZKkERvRPilzpt99Uj4E7Ad8r6qeBRwMXDGyqiRJ0siNalv8udJvSHmkqn4KLEqyqKouAfYeXVmSJGnUpioDH/Op3zkp9yXZFrgM+EySVQy5MYskSWrDqCbOzpV+OylHAL8Afhs4D/gn4DWjKkqSJI1e63NS+uqkVNXqGW/PGlEtkiRpHs338M2g+gopszZ1WwxsAax2MzdJkhau1od7+u2kPG5TtySvA/YdRUGSJGl+zPfwzaCGenZPVX01yUlzXcxs259x0ahvIWkd1q65c9wlSJoHm8pwz1Ez3i4ClrLuZ/pIkqQFYpMY7uHxK3nWMr3j7BFzXs0sL9j1xaO+haRZbrr7ah6557ZxlyF1zhY77znv99wkOinAp6rqcTvMJjkAWDX3JUmSJPW/T8on+jwnSZIWiBrimE/r7aQkeQmwP/CUJL8z40fbAZuNsjBJkjRaC324ZzGwbe9zM5chPwC8flRFSZKk0VvQE2er6lLg0iRnVtXt81STJEmaB1PjLmAD+p2T8qkkOzz2JsmOSc4fTUmSJGk+FBn4mE/9ru7Zuarue+xNVf0syS6jKUmSJM2HqcZ3POs3pEwleUZV3QGQZA/czE2SpAVtap47I4PqN6S8H7g8yaW99wcCE6MpSZIkzYf5Hr4ZVF9zUqrqPKa3wv8u8Hngd4FfjLAuSZI0YlNDHP1I8ttJbkqyIsmyJFsOU1+/z+75DeBEYHfgBmA/4ErgZcPcVJIkjd8oOilJdgPeBTy/qn6R5AvAG4EzB71Wv6t7TgT+I3B7Vb0U2Af4yaA3kyRJ7RhVJ4XpJshWSTYHtgbuGqa+fkPKw1X1MECSJ1XVLcBew9xQkiS1YRQhparuBP4SuAP4MXB/VV0wTH39hpSVvX1SvgpcmORrDJmKJElSG4bZJyXJRJJrZxyPW0iTZEfgCOBZwNOAbZIcM0x9fc1Jqaojey//OMklwPbAecPcUJIktWFqiCkpVTUJTK7nIy8HflBVPwFI8hWmnwN49qD36ncJ8sziLt3wpyRJUutGtE/KHcB+SbZmeiXwwcC1w1xo4JAiSZI2DaPYlbWqrk7yJeA6YC1wPevvvDwhQ4okSZpTVXUycPLGXseQIklSR7X+FGRDiiRJHTWVtrfFN6RIktRRrT8p2JAiSVJHOdwjSZKaNMw+KfPJkCJJUkeNaJ+UOWNIkSSpo5yTIkmSmuRwjyRJapITZyVJUpMc7pEkSU1yuEeSJDXJ4R5JktQkQ4okSWpSOdwjSZJaZCdFkiQ1yZAiSZKa1PoS5EXjLkCSJGld7KRIktRR7pMiSZKa5JwUSZLUpNZDinNSJEnqqBri2JAkeyW5YcbxQJJ3D1OfnRRJkjpqFHNSquq7wN4ASTYD7gSWD3MtQ4okSR01D8M9BwP/VFW3D/NlQ4okSR01D/ukvBFYNuyXnZMiSVJHTVEDH0kmklw745hY17WTLAZeC3xx2PrspEiS1FHDDPdU1SQw2cdHXwVcV1V3D3EbwJAiSVJnjXi452g2YqgHDCmSJHXWqCbOJtkaeAXwto25jiFFkqSOGtW2+FX1EPDkjb2OIUWSpI6aavw5yIYUSZI6qu2IYkiRJKmzWn92jyFFkqSOan24x83cJElSk+ykSJLUUW33UQwpkiR1lnNSJElSk1qfk2JIkSSpo9qOKIYUSZI6y+EeSZLUpGq8l2JIkSSpo+ykSJKkJjlxVp1ywTXLWb36IaYenWLt2kf51VceN+6SpE3WB/7so1x2xT+w04478NWz/wqAT0z+DX93+ZUsyiJ22nF7/vT9v8suT9noh9FqE9V2RDGkaASOP+od3Hfv/eMuQ9rkve6wV/Brv/Ja/uBDf/kv547/9V/hnRNvBuDsL36NT57xWU7+/XeOq0Q1rvVOitviS9ICtXTvX2b77ZY87ty222zzL69/8YuHSea7Ki0kU0Mc82neOylJjq+qM+b7vpofBfz15z9OFXzx08v54qe/Ou6SpM752Klncs55F7Nkm204/ROnjLscNaz11T3j6KR8cAz31Dw55tVv5Q2vOJa3/9q7Ofr41/Mf9tt73CVJnXPi247j4uWf5vBDXspnv/y/x12OGtZ6J2UkISXJjU9wfBvYdT3fm0hybZJrJycnR1GaRuwnd98DwL33/IyL/s83+OV9XjDmiqTuOvyQg7joG1eMuww1rIb4NZ9GNdyzK/BK4Gezzgf4+yf6UlVNAo+lk/rYH542muo0ElttvSXJIh5a/RBbbb0l+x/0Yv7qI/53KM2n2390J898+m4AXPLNq3jWM3cfc0VqWVf3Sfk6sG1V3TD7B0m+MaJ7asye/JSd+PgZfwHAZpttxrnLz+fyS64ac1XSpus9J5/CNdffyH33PcDBrzuGd5zwJr555TX88I6VZFF42r/ZhT96jyt79MSmqu05Kal2C6wX7Pricdcgdc5Nd1/NI/fcNu4ypM7ZYuc9YXrEYd686ZlHDRwCPn37V+atRpcgS5LUUTXE0Y8kOyT5UpJbktyc5CXD1OdmbpIkddQIN3P7GHBeVb0+yWJg62EuYkiRJKmjRrFaJ8l2wIHAcQBVtQZYM8y1HO6RJKmjhtknZeZ2Ib1jYtZl9wR+ApyR5Pokn0qyDUMwpEiS1FFT1MBHVU1W1dIZx+yNzTYH/j3wyaraB1gNnDRMfYYUSZI6akSbua0EVlbV1b33X2I6tAzMkCJJUkeNYlv8qvpn4EdJ9uqdOhj4zjD1OXFWkqSOGuFeae8EPtNb2XMbcPwwFzGkSJLUUaNagtzbcX7pxl7HkCJJUkd19dk9kiSpcfP9VONBGVIkSeqoEe44OycMKZIkdVTDDxkGDCmSJHWWc1IkSVKTnJMiSZKa1PqcFHeclSRJTbKTIklSRzlxVpIkNan14R5DiiRJHeXEWUmS1KQph3skSVKL2o4ohhRJkjrLOSmSJKlJhhRJktQklyBLkqQm2UmRJElNcgmyJElqksM9kiSpSQ73SJKkJtlJkSRJTRpVJyXJD4GfA48Ca6tq6TDXMaRIktRRI544+9KqumdjLmBIkSSpo1p/ds+icRcgSZI2OQVckORbSSaGvYidFEmSOmqY4Z5e6JgZPCaranLWxw6oqruS7AJcmOSWqrps0HsZUiRJ6qhhhnt6gWR2KJn9mbt6v69KshzYFxg4pDjcI0lSR9UQvzYkyTZJljz2GjgEWDFMfXZSJEnqqBFNnN0VWJ4EpnPGZ6vqvGEuZEiRJKmjRrEEuapuA140F9cypEiS1FGtL0E2pEiS1FE+BVmSJDWpamrcJayXIUWSpI7yKciSJKlJPgVZkiQ1yU6KJElqkp0USZLUJJcgS5KkJrkEWZIkNcnhHkmS1CQnzkqSpCa13klZNO4CJEmS1sVOiiRJHeXqHkmS1KTWh3sMKZIkdZQTZyVJUpPspEiSpCY5J0WSJDXJHWclSVKT7KRIkqQmtT4nxc3cJEnqqBriV7+SbJbk+iRfH7Y+OymSJHXUiDspJwI3A9sNewE7KZIkdVRVDXz0I8nuwOHApzamvqY7KTfdffW4S5A6aYud9xx3CZLmwQj7KP8d+H1gycZcpOWQknEXoOElmaiqyXHXIXWNf/c0iLVr7hz439okE8DEjFOTM/83l+TVwKqq+laSgzamvrQ+s1cLU5Jrq2rpuOuQusa/exq3JH8OvAlYC2zJ9JyUr1TVMYNeyzkpkiRpzlTV+6pq96raA3gj8HfDBBQwpEiSpEa1PCdFC5tj4tJ4+HdPzaiqbwDfGPb7zkmRJElNcrhHkiQ1yZCiOZXk0CTfTfL9JCeNux6pK5KcnmRVkhXjrkWaK4YUzZkkmwH/E3gV8Hzg6CTPH29VUmecCRw67iKkuWRI0VzaF/h+Vd1WVWuAzwFHjLkmqROq6jLg3nHXIc0lQ4rm0m7Aj2a8X9k7J0nSwAwpmkvr2l7Z5WOSpKEYUjSXVgJPn/F+d+CuMdUiSVrgDCmaS9cAz03yrCSLmd4O+Zwx1yRJWqAMKZozVbUW+C3gfOBm4AtVddN4q5K6Icky4EpgryQrk5ww7pqkjeWOs5IkqUl2UiRJUpMMKZIkqUmGFEmS1CRDiiRJapIhRZIkNcmQIokkByX5eu/1a9f3BOskOyR5xxD3+OMkv7cxdUrqFkOKtAnrPZl6IFV1TlWdsp6P7AAMHFIkaVCGFGmBSrJHkluSnJXkxiRfSrJ1kh8m+aMklwNvSHJIkiuTXJfki0m27X3/0N73LweOmnHd45L8j97rXZMsT/KPvWN/4BTg2UluSPLh3ufek+SaXh0fnHGt9yf5bpKLgL3m8T8eSZuAzcddgKSNshdwQlVdkeR0/rXD8XBV/ackOwNfAV5eVauTvBf4nSR/Afw18DLg+8Dnn+D6Hwcuraoje12ZbYGTgBdW1d4ASQ4Bngvsy/RDJs9JciCwmulHI+zD9P/XXAd8a27/+JI2ZYYUaWH7UVVd0Xt9NvCu3uvHQsd+wPOBK5IALGZ66/TnAT+oqlsBkpwNTKzj+i8D3gxQVY8C9yfZcdZnDukd1/feb8t0aFkCLK+qh3r38DlOkgZiSJEWttnPtXjs/ere7wEurKqjZ34oyd7r+O6wAvx5VZ066x7vnsN7SOog56RIC9szkryk9/po4PJZP78KOCDJcwB6c1Z+CbgFeFaSZ8/47rpcDPxm77ubJdkO+DnTXZLHnA+8ZcZcl92S7AJcBhyZZKskS4DXbMwfVFL3GFKkhe1m4NgkNwI7AZ+c+cOq+glwHLCs95mrgOdV1cNMD++c25s4e/sTXP9E4KVJvs30fJIXVNVPmR4+WpHkw1V1AfBZ4Mre574ELKmq65gedroB+DLwzTn8c0vqAJ+CLC1QSfYAvl5VLxx3LZI0CnZSJElSk+ykSJKkJtlJkSRJTTKkSJKkJhlSJElSkwwpkiSpSYYUSZLUJEOKJElq0v8Dxljr+ZehD34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=tf.math.confusion_matrix(labels=true_labels,predictions=predicted_class_indices)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sn.heatmap(cm,annot=True, linewidth=0.5)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for getting the predictions in a tabular form with image vs corresponding prediction, do this"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=prediction_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generating more images - for fun"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "path1=r'C:\\Users\\User\\Pictures\\Saved Pictures\\New folder'\n",
    "for i in os.listdir(path1):\n",
    "    newpath=os.path.join(path1,i)\n",
    "    img = load_img(newpath)  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1,3,150,150)  this reshapig is equiv to:  expand_dims(data, 0)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size=1, save_to_dir=r'C:\\Users\\User\\Desktop\\gen umages', save_prefix='pussy', save_format='jpeg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicting a single image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "path = r'C:\\Users\\User\\Desktop\\gen umages\\.jpeg'\n",
    "img = image.load_img(path, target_size=(300, 300))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(\"it is a human\")\n",
    "else:\n",
    "    print(\"it is a horse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=160\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model2 = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_160\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 161, 161, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 80, 80, 32)   864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 80, 80, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 80, 80, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 80, 80, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 80, 80, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 80, 80, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 80, 80, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 80, 80, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 80, 80, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 80, 80, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 80, 80, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 81, 81, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 40, 40, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 40, 40, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 40, 40, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 40, 40, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 40, 40, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 40, 40, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 40, 40, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 40, 40, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 40, 40, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 40, 40, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 40, 40, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 40, 40, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 40, 40, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 40, 40, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 40, 40, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 41, 41, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 20, 20, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 20, 20, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 20, 20, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 20, 20, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 20, 20, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 20, 20, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 20, 20, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 20, 20, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 20, 20, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 20, 20, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 20, 20, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 20, 20, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 20, 20, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 20, 20, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 20, 20, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 20, 20, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 20, 20, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 20, 20, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 20, 20, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 21, 21, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 10, 10, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 10, 10, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 10, 10, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 10, 10, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 10, 10, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 10, 10, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 10, 10, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 10, 10, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 10, 10, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 10, 10, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 10, 10, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 10, 10, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 10, 10, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 10, 10, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 10, 10, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 10, 10, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 10, 10, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 10, 10, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 10, 10, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 10, 10, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 10, 10, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 10, 10, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 10, 10, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 10, 10, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 10, 10, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 10, 10, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 10, 10, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 10, 10, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 10, 10, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 10, 10, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 10, 10, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 10, 10, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 10, 10, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 10, 10, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 10, 10, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 10, 10, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 10, 10, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 10, 10, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 10, 10, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 10, 10, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 10, 10, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 10, 10, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 10, 10, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 10, 10, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 11, 11, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 5, 5, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 5, 5, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 5, 5, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 5, 5, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 5, 5, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 5, 5, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 5, 5, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 5, 5, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 5, 5, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 5, 5, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 5, 5, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 5, 5, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 5, 5, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 5, 5, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 5, 5, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 5, 5, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 5, 5, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 5, 5, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 5, 5, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 5, 5, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 5, 5, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 5, 5, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 5, 5, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 5, 5, 1280)   0           Conv_1_bn[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.Sequential([\n",
    "  base_model2,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "new_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_model = tf.keras.models.Sequential([\n",
    "    base_model2,\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # hidden layers\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "new_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 74 images belonging to 2 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 8 steps, validate for 4 steps\n",
      "Epoch 1/25\n",
      "8/8 [==============================] - 7s 821ms/step - loss: 0.7612 - accuracy: 0.4945 - val_loss: 0.6646 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 3s 385ms/step - loss: 0.6784 - accuracy: 0.5166 - val_loss: 0.6361 - val_accuracy: 0.5156\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 3s 383ms/step - loss: 0.6343 - accuracy: 0.5543 - val_loss: 0.6133 - val_accuracy: 0.5625\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 3s 417ms/step - loss: 0.6312 - accuracy: 0.6152 - val_loss: 0.5881 - val_accuracy: 0.5781\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 3s 419ms/step - loss: 0.5947 - accuracy: 0.6445 - val_loss: 0.5634 - val_accuracy: 0.5781\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.5510 - accuracy: 0.6758 - val_loss: 0.5416 - val_accuracy: 0.6250\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 3s 412ms/step - loss: 0.5203 - accuracy: 0.7207 - val_loss: 0.5217 - val_accuracy: 0.6250\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 3s 352ms/step - loss: 0.4765 - accuracy: 0.7251 - val_loss: 0.5026 - val_accuracy: 0.6406\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 3s 414ms/step - loss: 0.4619 - accuracy: 0.7480 - val_loss: 0.4863 - val_accuracy: 0.6719\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 3s 402ms/step - loss: 0.4325 - accuracy: 0.8204 - val_loss: 0.4677 - val_accuracy: 0.7031\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 3s 390ms/step - loss: 0.4124 - accuracy: 0.8337 - val_loss: 0.4499 - val_accuracy: 0.7188\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 3s 375ms/step - loss: 0.3780 - accuracy: 0.8514 - val_loss: 0.4354 - val_accuracy: 0.7656\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 3s 389ms/step - loss: 0.3764 - accuracy: 0.8914 - val_loss: 0.4169 - val_accuracy: 0.7969\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 3s 415ms/step - loss: 0.3534 - accuracy: 0.8758 - val_loss: 0.4037 - val_accuracy: 0.8438\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 3s 388ms/step - loss: 0.3412 - accuracy: 0.9160 - val_loss: 0.3873 - val_accuracy: 0.8594\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 3s 435ms/step - loss: 0.3270 - accuracy: 0.9199 - val_loss: 0.3737 - val_accuracy: 0.8906\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 0.3000 - accuracy: 0.9316 - val_loss: 0.3607 - val_accuracy: 0.8906\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 3s 431ms/step - loss: 0.3029 - accuracy: 0.9199 - val_loss: 0.3480 - val_accuracy: 0.9219\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 3s 407ms/step - loss: 0.2858 - accuracy: 0.9277 - val_loss: 0.3366 - val_accuracy: 0.9219\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 3s 425ms/step - loss: 0.2647 - accuracy: 0.9395 - val_loss: 0.3267 - val_accuracy: 0.9531\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 4s 444ms/step - loss: 0.2544 - accuracy: 0.9570 - val_loss: 0.3130 - val_accuracy: 0.9531\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 3s 405ms/step - loss: 0.2492 - accuracy: 0.9446 - val_loss: 0.3047 - val_accuracy: 0.9531\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 4s 448ms/step - loss: 0.2262 - accuracy: 0.9648 - val_loss: 0.2946 - val_accuracy: 0.9531\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 3s 436ms/step - loss: 0.2191 - accuracy: 0.9707 - val_loss: 0.2826 - val_accuracy: 0.9531\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 4s 447ms/step - loss: 0.1998 - accuracy: 0.9805 - val_loss: 0.2724 - val_accuracy: 0.9531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x212247160c8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=16\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\horsehuman',     \n",
    "        target_size=(160, 160),  # All images will be resized to 300x300\n",
    "        batch_size=64,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\test',\n",
    "        target_size=(160, 160),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=8 ,\n",
    "        epochs=25,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=74 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 images belonging to 2 classes.\n",
      "32/32 [==============================] - 2s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_datagen = ImageDataGenerator(rescale=1./255)\n",
    "prediction_generator = predict_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\User\\Desktop\\new_images',\n",
    "        target_size=(160, 160),\n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "pred=new_model.predict_generator(\n",
    "        prediction_generator, \n",
    "        steps=len(prediction_generator),\n",
    "        verbose=1\n",
    "        )    # gives a 1d array of class probabilities. in this case, a single probability\n",
    "pred=pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for converting probailites into the corresponding predicted classes\n",
    "predicted_class_indices=[] \n",
    "for i in pred:\n",
    "    if i<0.5:\n",
    "        predicted_class_indices.append(0)\n",
    "    else:\n",
    "        predicted_class_indices.append(1)        \n",
    "# predicted_class_indices=np.argmax(pred,axis=1)   <- use this instead of above code if a multi class classification is used\n",
    "\n",
    "\n",
    "# for getting the actual class labels\n",
    "true_labels= [] \n",
    "classlabel=0\n",
    "for i in os.listdir(r'C:\\Users\\User\\Desktop\\new_images'):\n",
    "    j=os.path.join(r'C:\\Users\\User\\Desktop\\new_images',i)\n",
    "    l=len(os.listdir(j))\n",
    "    for k in range(l):\n",
    "        true_labels.append(classlabel)\n",
    "    classlabel+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'actual')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=tf.math.confusion_matrix(labels=true_labels,predictions=predicted_class_indices)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sn.heatmap(cm,annot=True, linewidth=0.5)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>horse\\download (1).jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horse\\download.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>horse\\photo-1485201567137-7771be2f710c.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>horse\\photo-1497781495506-ce58b286d8f5.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>horse\\photo-1504291310234-fdc312c67b04.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>horse\\photo-1504310977373-186d29f99322.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>horse\\photo-1511825869128-e85768033761.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>horse\\photo-1512397476661-a9ec6ffd4a93.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>horse\\photo-1513223848047-2456e15b4f7d.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>horse\\photo-1522564943606-a719b0859d58.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>horse\\photo-1545780699-605328d5e41b.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>horse\\photo-1548670385-de3e9a053ad2.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>horse\\photo-1563251981-25f42ed4b60b.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>horse\\photo-1590688304507-c7617bb49159.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>human\\IMG_20200708_153823.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>human\\images.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>human\\photo-1541647376583-8934aaf3448a.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>human\\photo-1542534759-05f6c34a9e63.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>human\\photo-1543080853-556086153871.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>human\\photo-1544005313-94ddf0286df2.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>human\\photo-1545167622-3a6ac756afa4.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>human\\photo-1545912453-db258ca9b7b7.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>human\\photo-1546820389-44d77e1f3b31.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>human\\photo-1547624643-3bf761b09502.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>human\\photo-1548543604-a87c9909abec.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>human\\photo-1549068106-b024baf5062d.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>human\\photo-1552058544-f2b08422138a.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>human\\photo-1554151228-14d9def656e4.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>human\\photo-1575632312417-71da8ed4992d.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>human\\photo-1578489758854-f134a358f08b.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>human\\photo-1594270410221-e6a33cbc6fb9.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>human\\photo-1595412212084-cc97030c594d.jpg</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Filename Predictions\n",
       "0                       horse\\download (1).jpg       horse\n",
       "1                           horse\\download.jpg       horse\n",
       "2   horse\\photo-1485201567137-7771be2f710c.jpg       horse\n",
       "3   horse\\photo-1497781495506-ce58b286d8f5.jpg       horse\n",
       "4   horse\\photo-1504291310234-fdc312c67b04.jpg       horse\n",
       "5   horse\\photo-1504310977373-186d29f99322.jpg       human\n",
       "6   horse\\photo-1511825869128-e85768033761.jpg       horse\n",
       "7   horse\\photo-1512397476661-a9ec6ffd4a93.jpg       horse\n",
       "8   horse\\photo-1513223848047-2456e15b4f7d.jpg       horse\n",
       "9   horse\\photo-1522564943606-a719b0859d58.jpg       horse\n",
       "10     horse\\photo-1545780699-605328d5e41b.jpg       horse\n",
       "11     horse\\photo-1548670385-de3e9a053ad2.jpg       horse\n",
       "12     horse\\photo-1563251981-25f42ed4b60b.jpg       horse\n",
       "13  horse\\photo-1590688304507-c7617bb49159.jpg       horse\n",
       "14               human\\IMG_20200708_153823.jpg       human\n",
       "15                            human\\images.jpg       human\n",
       "16  human\\photo-1541647376583-8934aaf3448a.jpg       human\n",
       "17     human\\photo-1542534759-05f6c34a9e63.jpg       human\n",
       "18     human\\photo-1543080853-556086153871.jpg       human\n",
       "19     human\\photo-1544005313-94ddf0286df2.jpg       human\n",
       "20     human\\photo-1545167622-3a6ac756afa4.jpg       human\n",
       "21     human\\photo-1545912453-db258ca9b7b7.jpg       horse\n",
       "22     human\\photo-1546820389-44d77e1f3b31.jpg       human\n",
       "23     human\\photo-1547624643-3bf761b09502.jpg       human\n",
       "24     human\\photo-1548543604-a87c9909abec.jpg       horse\n",
       "25     human\\photo-1549068106-b024baf5062d.jpg       human\n",
       "26     human\\photo-1552058544-f2b08422138a.jpg       human\n",
       "27     human\\photo-1554151228-14d9def656e4.jpg       horse\n",
       "28  human\\photo-1575632312417-71da8ed4992d.jpg       human\n",
       "29  human\\photo-1578489758854-f134a358f08b.jpg       horse\n",
       "30  human\\photo-1594270410221-e6a33cbc6fb9.jpg       human\n",
       "31  human\\photo-1595412212084-cc97030c594d.jpg       human"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=prediction_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
